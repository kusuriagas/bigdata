{
  "metadata": {
    "name": "ProjectBigData v 0.0.1",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\n\nimport org.apache.spark.sql.SparkSession\nimport org.apache.spark.sql.types.{StructType, StructField}\nimport org.apache.spark.sql.types.{StringType, IntegerType, DoubleType}\nimport org.apache.spark.sql.types._\nimport org.apache.spark.sql.{functions \u003d\u003e f}\n\n\n//Definimos la reserva\nvar spark \u003d SparkSession.builder.\nappName(\"Mi Aplicacion\").\nconfig(\"spark.driver.memory\", \"1g\").\nconfig(\"spark.dynamicAllocation.maxExecutors\", \"10\").\nconfig(\"spark.executor.cores\", \"2\").\nconfig(\"spark.executor.memory\", \"2g\").\nconfig(\"spark.executor.memoryOverhead\", \"1g\").\nenableHiveSupport().\ngetOrCreate()\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "//lectura\nvar dfcategories \u003d spark.read.format(\"csv\").option(\"header\", \"true\").option(\"delimiter\", \",\").schema(\n    StructType(\n        Array(\n            StructField(\"category_id\", IntegerType, false),\n            StructField(\"category_name\", StringType, true),\n            StructField(\"description\", StringType, true)\n        )\n    )\n).load(\"gs://repositorio_bigdata/datalake/landingtemp/categories/categories.csv\")\n\ndfcategories.show()\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "var dfproducts \u003d spark.read.format(\"csv\").option(\"header\", \"true\").option(\"delimiter\", \",\").schema(\n    StructType(\n        Array(\n            StructField(\"product_id\", IntegerType, false),\n            StructField(\"product_name\", StringType, true),\n            StructField(\"supplier_id\", IntegerType, true),\n            StructField(\"category_id\", IntegerType, true),\n            StructField(\"quantity_per_unit\", StringType, true),\n            StructField(\"unit_price\", DoubleType, true),\n            StructField(\"units_in_stock\", IntegerType, true)\n        )\n    )\n).load(\"gs://repositorio_bigdata/datalake/landingtemp/products/products.csv\")\n\ndfproducts.show()\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "var dforders_details \u003d spark.read.format(\"csv\").option(\"header\", \"true\").option(\"delimiter\", \",\").schema(\n    StructType(\n        Array(\n            StructField(\"order_id\", IntegerType, false),\n            StructField(\"product_id\", IntegerType, true),\n            StructField(\"unit_price\", DoubleType, true),\n            StructField(\"quantity\", IntegerType, true),\n            StructField(\"discount\", DoubleType, true)\n        )\n    )\n).load(\"gs://repositorio_bigdata/datalake/landingtemp/orders_details/order_details.csv\")\n\n\ndforders_details.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "var dforders \u003d spark.read.format(\"csv\")\n                        .option(\"header\", \"true\")\n                        .option(\"delimiter\", \",\")\n                        .option(\"encoding\", \"ISO-8859-1\")\n                        .schema(\n    StructType(\n        Array(\n            StructField(\"order_id\", IntegerType, true),\n            StructField(\"customer_id\", IntegerType, true),\n            StructField(\"employee_id\", StringType, true),\n            StructField(\"order_date\", StringType, true),\n            StructField(\"required_date\", StringType, true),\n            StructField(\"shipped_date\", StringType, true),\n           // StructField(\"ship_via\", IntegerType, true),\n            //StructField(\"freight\", DoubleType, true),\n            //StructField(\"ship_name\", StringType, true),\n            //StructField(\"ship_address\", StringType, true),\n            //StructField(\"ship_city\", StringType, true),\n            //StructField(\"ship_region\", StringType, true),\n            //StructField(\"ship_postal_code\", StringType, true),\n            StructField(\"ship_country\", StringType, true)\n        )\n    )\n).load(\"gs://repositorio_bigdata/datalake/landingtemp/orders/orders.csv\")\n\n\ndforders.show()\n\n\ndforders.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "var dfcustomers \u003d spark.read.format(\"csv\").option(\"header\", \"true\").option(\"delimiter\", \",\").schema(\n    StructType(\n        Array(\n            StructField(\"customer_id\", StringType, true),\n            StructField(\"company_name\", StringType, true),\n            StructField(\"contact_name\", StringType, true),\n            StructField(\"contact_title\", StringType, true),\n            StructField(\"address\", StringType, true),\n            StructField(\"city\", StringType, true),\n            StructField(\"region\", StringType, true),\n            StructField(\"postal_code\", StringType, true),\n            StructField(\"country\", StringType, true),\n            StructField(\"phone\", StringType, true),\n            StructField(\"fax\", StringType, true)\n        )\n    )\n).load(\"gs://repositorio_bigdata/datalake/landingtemp/customers/customers.csv\")\n\n\ndfcustomers.show()\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "var dfemployees \u003d spark.read.format(\"csv\").option(\"header\", \"true\").option(\"delimiter\", \",\").schema(\n    \n    \n    StructType(\n        Array(\n            StructField(\"employee_id\", StringType, true),\n            StructField(\"last_name\", StringType, true),\n            StructField(\"first_name\", StringType, true),\n            StructField(\"title\", StringType, true),\n            StructField(\"title_of_courtesy\", StringType, true),\n            StructField(\"birth_date\", StringType, true),\n            StructField(\"hire_date\", StringType, true),\n            StructField(\"address\", StringType, true),\n            StructField(\"city\", StringType, true),\n            StructField(\"region\", StringType, true),\n            StructField(\"postal_code\", StringType, true),\n            StructField(\"country\", StringType, true),\n            StructField(\"home_phone\", StringType, true)\n            \n        )\n    )\n).load(\"gs://repositorio_bigdata/datalake/landingtemp/employees/employees.csv\")\n\n\ndfemployees.show()"
    }
  ]
}